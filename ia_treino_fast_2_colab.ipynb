{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769e1860",
   "metadata": {},
   "source": [
    "# üöÄ IA TREINO FAST 2 - GOOGLE COLAB\n",
    "## Treinamento de Segmenta√ß√£o de Estradas com U-Net Otimizada\n",
    "\n",
    "### üìã O que este notebook faz:\n",
    "- Treina uma U-Net profunda para detectar estradas em imagens\n",
    "- Salva o modelo treinado para reutiliza√ß√£o\n",
    "- Cria compara√ß√µes de TODAS as imagens de valida√ß√£o\n",
    "- Gera grid completo com todas as compara√ß√µes\n",
    "- Otimiza automaticamente o threshold de detec√ß√£o\n",
    "\n",
    "### üéØ Arquitetura do modelo:\n",
    "- **Encoder:** 64‚Üí128‚Üí256‚Üí512 neur√¥nios\n",
    "- **Decoder:** 512‚Üí256‚Üí128‚Üí64‚Üí1 neur√¥nios\n",
    "- **Skip connections** para preservar detalhes\n",
    "- **Batch normalization** e **Dropout** para estabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfa637",
   "metadata": {},
   "source": [
    "## üì¶ 1. Instala√ß√£o e Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar bibliotecas necess√°rias\n",
    "!pip install opencv-python-headless matplotlib scikit-learn tensorflow\n",
    "\n",
    "print(\"‚úÖ Bibliotecas instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas as bibliotecas necess√°rias\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"üöÄ IA TREINO FAST 2 - VERS√ÉO COLAB\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üì± TensorFlow vers√£o: {tf.__version__}\")\n",
    "print(f\"üîß GPU dispon√≠vel: {len(tf.config.list_physical_devices('GPU'))} GPU(s)\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"   ‚Ä¢ {tf.config.list_physical_devices('GPU')[0].name}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Nenhuma GPU detectada - usando CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5829d6",
   "metadata": {},
   "source": [
    "## üìÅ 2. Configura√ß√£o e Upload dos Dados\n",
    "\n",
    "### üì§ Para usar este notebook:\n",
    "1. **Crie um arquivo ZIP** com suas pastas `dataset/` e `mascara/`\n",
    "2. **Execute a c√©lula abaixo** para fazer upload\n",
    "3. **O notebook ir√° extrair automaticamente** os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ab132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes\n",
    "images_folder = 'dataset'\n",
    "masks_folder = 'mascara'\n",
    "output_folder = 'fast2'\n",
    "\n",
    "print(\"üìÅ Configurando pastas...\")\n",
    "print(f\"   ‚Ä¢ Imagens: {images_folder}/\")\n",
    "print(f\"   ‚Ä¢ M√°scaras: {masks_folder}/\")\n",
    "print(f\"   ‚Ä¢ Resultados: {output_folder}/\")\n",
    "\n",
    "# Criar pasta de resultados\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "print(f\"‚úÖ Pasta de resultados criada: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe36f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload e extra√ß√£o dos dados\n",
    "print(\"üì§ UPLOAD DOS DADOS\")\n",
    "print(\"Por favor, fa√ßa upload do arquivo ZIP contendo as pastas 'dataset' e 'mascara'\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extrair arquivos ZIP\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"üì¶ Extraindo: {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print(f\"‚úÖ {filename} extra√≠do com sucesso!\")\n",
    "\n",
    "# Verificar se as pastas existem\n",
    "if os.path.exists(images_folder) and os.path.exists(masks_folder):\n",
    "    print(f\"‚úÖ Pastas encontradas:\")\n",
    "    print(f\"   ‚Ä¢ {images_folder}/: {len(os.listdir(images_folder))} arquivos\")\n",
    "    print(f\"   ‚Ä¢ {masks_folder}/: {len(os.listdir(masks_folder))} arquivos\")\n",
    "else:\n",
    "    print(\"‚ùå Erro: Pastas 'dataset' ou 'mascara' n√£o encontradas!\")\n",
    "    print(\"   Certifique-se de que o ZIP cont√©m essas pastas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a48b0",
   "metadata": {},
   "source": [
    "## üîß 3. Fun√ß√µes de Carregamento de Dados e Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_otimizado(limit=None):\n",
    "    \"\"\"Carrega dados com verifica√ß√µes melhoradas\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    all_image_files = sorted(os.listdir(images_folder))\n",
    "    if limit is None:\n",
    "        image_files = all_image_files\n",
    "        print(f\"üîç Carregando TODAS as {len(all_image_files)} imagens do dataset...\")\n",
    "    else:\n",
    "        image_files = all_image_files[:limit]\n",
    "        print(f\"üîç Carregando at√© {limit} imagens...\")\n",
    "    \n",
    "    for i, image_file in enumerate(image_files):\n",
    "        base_name, ext = os.path.splitext(image_file)\n",
    "        mask_file = base_name + '_mask' + ext\n",
    "        \n",
    "        image_path = os.path.join(images_folder, image_file)\n",
    "        mask_path = os.path.join(masks_folder, mask_file)\n",
    "        \n",
    "        if os.path.exists(image_path) and os.path.exists(mask_path):\n",
    "            # Carregar imagem\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Carregar m√°scara\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                continue\n",
    "                \n",
    "            mask = cv2.resize(mask, (128, 128))\n",
    "            \n",
    "            # Verificar se m√°scara tem conte√∫do\n",
    "            if mask.max() > 0:\n",
    "                mask = (mask > 0).astype(np.float32)\n",
    "                mask = np.expand_dims(mask, axis=-1)\n",
    "                \n",
    "                images.append(img)\n",
    "                masks.append(mask)\n",
    "                \n",
    "                mask_pixels = np.sum(mask)\n",
    "                if i % 5 == 0:  # Mostrar progresso a cada 5 imagens\n",
    "                    print(f\"   ‚úì {image_file}: {mask_pixels:.0f} pixels de estrada\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è {image_file}: M√°scara vazia, pulando...\")\n",
    "    \n",
    "    print(f\"‚úÖ Carregamento conclu√≠do: {len(images)} imagens v√°lidas\")\n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_fast_otimizado(input_size=(128, 128, 3)):\n",
    "    \"\"\"U-Net MELHORADA - Mais camadas e skip connections\"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder - MELHORADO com mais camadas\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, 3, activation='relu', padding='same')(c1)  # Camada dupla\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, 3, activation='relu', padding='same')(c2)  # Camada dupla\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, 3, activation='relu', padding='same')(c3)  # Camada dupla\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    # Bottleneck - Mais profundo\n",
    "    c4 = Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Dropout(0.3)(c4)  # Dropout mais forte\n",
    "    \n",
    "    # Decoder - MELHORADO com skip connections\n",
    "    u5 = UpSampling2D((2, 2))(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Conv2D(256, 3, activation='relu', padding='same')(u5)\n",
    "    c5 = Conv2D(256, 3, activation='relu', padding='same')(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    \n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv2D(128, 3, activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(128, 3, activation='relu', padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    \n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Conv2D(64, 3, activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(64, 3, activation='relu', padding='same')(c7)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(c7)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Fun√ß√£o de modelo U-Net definida!\")\n",
    "print(\"üß† Arquitetura: 64‚Üí128‚Üí256‚Üí512‚Üí256‚Üí128‚Üí64‚Üí1 neur√¥nios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee3a2a8",
   "metadata": {},
   "source": [
    "## üéØ 4. Carregamento de Dados e Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "print(\"üìä CARREGANDO DATASET...\")\n",
    "images, masks = load_data_otimizado()  # TODAS as imagens do dataset\n",
    "\n",
    "if len(images) == 0:\n",
    "    print(\"‚ùå Nenhuma imagem carregada! Verifique os dados.\")\n",
    "    raise Exception(\"Dados n√£o carregados\")\n",
    "\n",
    "print(f\"üìä Total de imagens carregadas: {len(images)}\")\n",
    "print(f\"üìè Formato das imagens: {images.shape}\")\n",
    "print(f\"üìè Formato das m√°scaras: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e compilar modelo\n",
    "print(\"üîß Criando modelo U-Net Fast Otimizado...\")\n",
    "model = unet_fast_otimizado()\n",
    "\n",
    "# Compilar com configura√ß√µes MELHORADAS\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Learning rate menor\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']  # Mais m√©tricas\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modelo criado e compilado!\")\n",
    "print(f\"üî¢ Total de par√¢metros: {model.count_params():,}\")\n",
    "\n",
    "# Mostrar resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados e treinar\n",
    "print(\"üéØ Iniciando treinamento otimizado...\")\n",
    "\n",
    "if len(images) >= 8:\n",
    "    # Dividir em treino/valida√ß√£o\n",
    "    train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "        images, masks, test_size=0.15, random_state=42  # 15% para valida√ß√£o\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Dataset dividido:\")\n",
    "    print(f\"   ‚Ä¢ Treino: {len(train_images)} imagens\")\n",
    "    print(f\"   ‚Ä¢ Valida√ß√£o: {len(val_images)} imagens\")\n",
    "    \n",
    "    # Treinamento\n",
    "    history = model.fit(\n",
    "        train_images, train_masks,\n",
    "        epochs=50,  # MAIS epochs para aprender melhor\n",
    "        validation_data=(val_images, val_masks),\n",
    "        verbose=1,\n",
    "        batch_size=1  # Batch menor para melhor aprendizado\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    # Poucos dados, treinar sem valida√ß√£o\n",
    "    print(\"‚ö†Ô∏è Poucos dados - treinando sem valida√ß√£o\")\n",
    "    history = model.fit(\n",
    "        images, masks,\n",
    "        epochs=30,\n",
    "        verbose=1,\n",
    "        batch_size=1\n",
    "    )\n",
    "    # Usar todas as imagens para valida√ß√£o\n",
    "    val_images = images\n",
    "    val_masks = masks\n",
    "\n",
    "print(\"‚úÖ Treinamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAR O MODELO TREINADO\n",
    "model_path = os.path.join(output_folder, 'modelo_fast2.h5')\n",
    "model.save(model_path)\n",
    "print(f\"üéØ Modelo salvo em: {model_path}\")\n",
    "\n",
    "# Plotar hist√≥rico de treinamento\n",
    "if 'val_loss' in history.history:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Treino')\n",
    "    plt.plot(history.history['val_loss'], label='Valida√ß√£o')\n",
    "    plt.title('Loss do Modelo')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Treino')\n",
    "    plt.plot(history.history['val_accuracy'], label='Valida√ß√£o')\n",
    "    plt.title('Acur√°cia do Modelo')\n",
    "    plt.xlabel('√âpoca')\n",
    "    plt.ylabel('Acur√°cia')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'historico_treinamento.png'), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734f144",
   "metadata": {},
   "source": [
    "## üîÆ 5. Previs√µes e Otimiza√ß√£o de Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previs√£o EM TODAS AS IMAGENS DE VALIDA√á√ÉO\n",
    "print(\"üîÆ Fazendo previs√µes em TODAS as imagens de valida√ß√£o...\")\n",
    "print(f\"üìä Total de imagens para processar: {len(val_images)}\")\n",
    "\n",
    "# Processar todas as imagens de valida√ß√£o\n",
    "all_predictions = []\n",
    "for i, val_img in enumerate(val_images):\n",
    "    test_image_input = np.expand_dims(val_img, axis=0)\n",
    "    predicted_mask = model.predict(test_image_input, verbose=0)\n",
    "    all_predictions.append(predicted_mask[0])\n",
    "    if i % 5 == 0:  # Mostrar progresso a cada 5 imagens\n",
    "        print(f\"   ‚úì Processada imagem {i+1}/{len(val_images)}\")\n",
    "\n",
    "print(f\"‚úÖ Todas as {len(all_predictions)} previs√µes conclu√≠das!\")\n",
    "\n",
    "# Estat√≠sticas das previs√µes\n",
    "print(f\"üìä Estat√≠sticas resumidas:\")\n",
    "all_mins = [pred.min() for pred in all_predictions]\n",
    "all_maxs = [pred.max() for pred in all_predictions]\n",
    "all_means = [pred.mean() for pred in all_predictions]\n",
    "\n",
    "print(f\"   ‚Ä¢ Min geral: {min(all_mins):.4f} - {max(all_mins):.4f}\")\n",
    "print(f\"   ‚Ä¢ Max geral: {min(all_maxs):.4f} - {max(all_maxs):.4f}\")\n",
    "print(f\"   ‚Ä¢ M√©dia geral: {min(all_means):.4f} - {max(all_means):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar thresholds na primeira imagem\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "print(f\"üéöÔ∏è Testando thresholds na primeira imagem:\")\n",
    "\n",
    "predicted_mask = all_predictions[0]\n",
    "resultados_threshold = {}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    mask_test = (predicted_mask > thresh).astype(np.uint8)\n",
    "    white_pixels = np.sum(mask_test)\n",
    "    percentage = (white_pixels / (128*128)) * 100\n",
    "    \n",
    "    resultados_threshold[thresh] = {\n",
    "        'pixels': white_pixels,\n",
    "        'percentage': percentage,\n",
    "        'mask': mask_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Threshold {thresh}: {white_pixels} pixels ({percentage:.1f}%)\")\n",
    "\n",
    "# Escolher melhor threshold\n",
    "best_threshold = 0.3\n",
    "best_score = 0\n",
    "\n",
    "for thresh, dados in resultados_threshold.items():\n",
    "    percentage = dados['percentage']\n",
    "    # Score baseado em ter entre 2% e 30% da imagem detectada\n",
    "    if 2 <= percentage <= 30:\n",
    "        score = 100 - abs(percentage - 12)  # Ideal em torno de 12%\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thresh\n",
    "\n",
    "print(f\"\\nüèÜ Melhor threshold escolhido: {best_threshold}\")\n",
    "best_percentage = (np.sum((predicted_mask > best_threshold).astype(np.uint8)) / (128*128)) * 100\n",
    "print(f\"   ‚Ä¢ Detec√ß√£o: {best_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b87b4",
   "metadata": {},
   "source": [
    "## üñºÔ∏è 6. Gera√ß√£o de Resultados e Compara√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f851ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIAR COMPARA√á√ïES LADO A LADO DE TODAS AS IMAGENS\n",
    "print(f\"üñºÔ∏è Criando compara√ß√µes lado a lado de TODAS as {len(val_images)} imagens...\")\n",
    "\n",
    "# Criar pasta espec√≠fica para compara√ß√µes\n",
    "comparacoes_folder = os.path.join(output_folder, 'comparacoes_todas')\n",
    "os.makedirs(comparacoes_folder, exist_ok=True)\n",
    "\n",
    "# Processar cada imagem de valida√ß√£o\n",
    "for i in range(len(val_images)):\n",
    "    val_img = val_images[i]\n",
    "    val_mask_real = val_masks[i]\n",
    "    predicted_mask_img = all_predictions[i]\n",
    "    \n",
    "    # Aplicar melhor threshold\n",
    "    best_mask = (predicted_mask_img > best_threshold).astype(np.uint8)\n",
    "    \n",
    "    # Converter para BGR para salvar\n",
    "    original_bgr = cv2.cvtColor(val_img, cv2.COLOR_RGB2BGR)\n",
    "    original_display = (original_bgr * 255).astype(np.uint8)\n",
    "    \n",
    "    # Converter m√°scaras para 3 canais\n",
    "    mask_real_3ch = cv2.cvtColor((val_mask_real.squeeze() * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "    mask_pred_3ch = cv2.cvtColor((best_mask.squeeze() * 255).astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Criar compara√ß√£o lado a lado: Original | Real | Prevista\n",
    "    comparison = np.hstack((original_display, mask_real_3ch, mask_pred_3ch))\n",
    "    \n",
    "    # Salvar compara√ß√£o individual\n",
    "    comparison_path = os.path.join(comparacoes_folder, f'comparacao_{i+1:02d}.png')\n",
    "    cv2.imwrite(comparison_path, comparison)\n",
    "    \n",
    "    # Salvar tamb√©m as imagens individuais\n",
    "    individual_folder = os.path.join(comparacoes_folder, f'imagem_{i+1:02d}')\n",
    "    os.makedirs(individual_folder, exist_ok=True)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(individual_folder, 'original.png'), original_display)\n",
    "    cv2.imwrite(os.path.join(individual_folder, 'mascara_real.png'), mask_real_3ch)\n",
    "    cv2.imwrite(os.path.join(individual_folder, 'mascara_prevista.png'), mask_pred_3ch)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(f\"   ‚úì Compara√ß√£o {i+1}/{len(val_images)} salva\")\n",
    "\n",
    "print(f\"‚úÖ Todas as {len(val_images)} compara√ß√µes individuais criadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma imagem GRID com todas as compara√ß√µes\n",
    "print(\"üî• Criando GRID com todas as compara√ß√µes...\")\n",
    "\n",
    "# Calcular dimens√µes do grid\n",
    "num_images = min(len(val_images), 16)  # Limitar a 16 imagens para o grid\n",
    "cols = min(4, num_images)  # M√°ximo 4 colunas\n",
    "rows = (num_images + cols - 1) // cols  # Arredondar para cima\n",
    "\n",
    "print(f\"üìê Grid: {rows}x{cols} = {rows*cols} imagens\")\n",
    "\n",
    "# Criar grid grande\n",
    "grid_height = rows * 128\n",
    "grid_width = cols * (128 * 3)  # 3 por causa do lado a lado (original+real+prevista)\n",
    "grid = np.zeros((grid_height, grid_width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(num_images):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    \n",
    "    val_img = val_images[i]\n",
    "    val_mask_real = val_masks[i]\n",
    "    predicted_mask_img = all_predictions[i]\n",
    "    best_mask = (predicted_mask_img > best_threshold).astype(np.uint8)\n",
    "    \n",
    "    # Preparar imagens pequenas para o grid\n",
    "    original_small = cv2.resize((cv2.cvtColor(val_img, cv2.COLOR_RGB2BGR) * 255).astype(np.uint8), (128, 128))\n",
    "    real_small = cv2.resize((val_mask_real.squeeze() * 255).astype(np.uint8), (128, 128))\n",
    "    pred_small = cv2.resize((best_mask.squeeze() * 255).astype(np.uint8), (128, 128))\n",
    "    \n",
    "    # Converter para 3 canais\n",
    "    real_small_3ch = cv2.cvtColor(real_small, cv2.COLOR_GRAY2BGR)\n",
    "    pred_small_3ch = cv2.cvtColor(pred_small, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Posi√ß√£o no grid\n",
    "    y_start = row * 128\n",
    "    y_end = y_start + 128\n",
    "    x_start = col * (128 * 3)\n",
    "    \n",
    "    # Colocar as 3 imagens lado a lado\n",
    "    grid[y_start:y_end, x_start:x_start+128] = original_small\n",
    "    grid[y_start:y_end, x_start+128:x_start+256] = real_small_3ch\n",
    "    grid[y_start:y_end, x_start+256:x_start+384] = pred_small_3ch\n",
    "\n",
    "# Salvar grid completo\n",
    "grid_path = os.path.join(output_folder, 'grid_todas_comparacoes.png')\n",
    "cv2.imwrite(grid_path, grid)\n",
    "\n",
    "print(f\"üéâ Grid completo criado: {grid_path}\")\n",
    "\n",
    "# Mostrar o grid no notebook\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(cv2.cvtColor(grid, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Grid Completo - {num_images} Compara√ß√µes\\n(Original | Real | Prevista)', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados principais (primeira imagem)\n",
    "print(f\"üíæ Salvando resultados principais...\")\n",
    "\n",
    "# Usar primeira imagem para an√°lises principais\n",
    "test_image = val_images[0]\n",
    "test_mask_real = val_masks[0]\n",
    "predicted_mask = all_predictions[0]\n",
    "\n",
    "# 1. Imagem original (primeira de valida√ß√£o)\n",
    "original_bgr = cv2.cvtColor(test_image, cv2.COLOR_RGB2BGR)\n",
    "original_path = os.path.join(output_folder, 'imagem_original.png')\n",
    "cv2.imwrite(original_path, (original_bgr * 255).astype(np.uint8))\n",
    "\n",
    "# 2. M√°scara prevista (melhor threshold) - primeira imagem\n",
    "best_mask = (predicted_mask > best_threshold).astype(np.uint8)\n",
    "mask_to_save = (best_mask.squeeze() * 255).astype(np.uint8)\n",
    "mask_path = os.path.join(output_folder, f'mascara_prevista_threshold_{best_threshold}.png')\n",
    "cv2.imwrite(mask_path, mask_to_save)\n",
    "\n",
    "# 3. M√°scara real\n",
    "real_mask = (test_mask_real.squeeze() * 255).astype(np.uint8)\n",
    "real_mask_path = os.path.join(output_folder, 'mascara_real.png')\n",
    "cv2.imwrite(real_mask_path, real_mask)\n",
    "\n",
    "# 4. Todas as m√°scaras por threshold (primeira imagem)\n",
    "for thresh in thresholds:\n",
    "    thresh_mask_result = (predicted_mask > thresh).astype(np.uint8)\n",
    "    thresh_mask = (thresh_mask_result.squeeze() * 255).astype(np.uint8)\n",
    "    thresh_path = os.path.join(output_folder, f'mascara_threshold_{thresh:.2f}.png')\n",
    "    cv2.imwrite(thresh_path, thresh_mask)\n",
    "\n",
    "print(\"‚úÖ Arquivos principais salvos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1642a",
   "metadata": {},
   "source": [
    "## üìä 7. Visualiza√ß√£o e An√°lise Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualiza√ß√£o final\n",
    "try:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # Plot principal: Original, Real, Melhor Prevista\n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.imshow(test_image)\n",
    "    plt.title('Imagem Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.imshow(test_mask_real.squeeze(), cmap='gray')\n",
    "    plt.title('M√°scara Real')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 4, 3)\n",
    "    plt.imshow(best_mask.squeeze(), cmap='gray')\n",
    "    plt.title(f'Melhor Prevista\\n(Threshold {best_threshold})')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Compara√ß√£o lado a lado\n",
    "    mask_3ch = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2BGR)\n",
    "    real_mask_3ch = cv2.cvtColor(real_mask, cv2.COLOR_GRAY2BGR)\n",
    "    original_display = (original_bgr * 255).astype(np.uint8)\n",
    "    comparison = np.hstack((original_display, real_mask_3ch, mask_3ch))\n",
    "    \n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.imshow(cv2.cvtColor(comparison, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original | Real | Prevista')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Mostrar diferentes thresholds\n",
    "    for i, thresh in enumerate([0.1, 0.2, 0.3, 0.4]):\n",
    "        if thresh in thresholds:  # Verificar se threshold existe\n",
    "            plt.subplot(2, 4, 5 + i)\n",
    "            thresh_mask_plot = (predicted_mask > thresh).astype(np.uint8)\n",
    "            plt.imshow(thresh_mask_plot.squeeze(), cmap='gray')\n",
    "            white_pixels = np.sum(thresh_mask_plot)\n",
    "            percentage = (white_pixels / (128*128)) * 100\n",
    "            plt.title(f'Threshold {thresh}\\n{percentage:.1f}%')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(output_folder, 'analise_completa.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ An√°lise visual salva em: {plot_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao criar visualiza√ß√£o: {e}\")\n",
    "\n",
    "# Salvar compara√ß√£o lado a lado\n",
    "comparison_path = os.path.join(output_folder, 'comparacao_lado_a_lado.png')\n",
    "cv2.imwrite(comparison_path, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac83aa0",
   "metadata": {},
   "source": [
    "## üì• 8. Download dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados finais\n",
    "print(f\"\\nüéâ RESULTADOS FINAIS:\")\n",
    "print(f\"   üìÅ Pasta: {output_folder}/\")\n",
    "print(f\"   üéØ Melhor threshold: {best_threshold}\")\n",
    "print(f\"   üìä Detec√ß√£o: {best_percentage:.1f}%\")\n",
    "print(f\"   üñºÔ∏è Arquivos principais:\")\n",
    "print(f\"      ‚Ä¢ {mask_path}\")\n",
    "print(f\"      ‚Ä¢ {comparison_path}\")\n",
    "print(f\"      ‚Ä¢ analise_completa.png\")\n",
    "print(f\"      ‚Ä¢ {model_path} (MODELO TREINADO)\")\n",
    "print(f\"   üî• NOVIDADES:\")\n",
    "print(f\"      ‚Ä¢ {grid_path} (GRID COM TODAS)\")\n",
    "print(f\"      ‚Ä¢ {comparacoes_folder}/ (COMPARA√á√ïES INDIVIDUAIS)\")\n",
    "print(f\"      ‚Ä¢ Total de {len(val_images)} imagens processadas!\")\n",
    "\n",
    "print(f\"\\nüí° Para usar este threshold no script principal:\")\n",
    "print(f\"   predicted_mask_binary = (predicted_mask > {best_threshold}).astype(np.uint8)\")\n",
    "\n",
    "print(f\"\\nüöÄ Para carregar o modelo salvo:\")\n",
    "print(f\"   from tensorflow.keras.models import load_model\")\n",
    "print(f\"   model = load_model('{model_path}')\")\n",
    "\n",
    "# Listar todos os arquivos criados\n",
    "print(f\"\\nüìã Arquivos criados em {output_folder}/:\")\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    level = root.replace(output_folder, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f\"{subindent}{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar ZIP para download\n",
    "print(\"üì¶ Criando arquivo ZIP para download...\")\n",
    "\n",
    "zip_filename = 'resultados_fast2.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    # Adicionar todos os arquivos da pasta de resultados\n",
    "    for root, dirs, files in os.walk(output_folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, os.path.dirname(output_folder))\n",
    "            zipf.write(file_path, arcname)\n",
    "\n",
    "print(f\"‚úÖ ZIP criado: {zip_filename}\")\n",
    "\n",
    "# Download do arquivo ZIP\n",
    "print(\"‚¨áÔ∏è Iniciando download...\")\n",
    "files.download(zip_filename)\n",
    "\n",
    "print(\"üéâ PROCESSO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"‚úÖ Todos os resultados foram baixados para seu computador!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
