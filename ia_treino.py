# -*- coding: utf-8 -*-
"""IA-TREINO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hUOEDUAtikvDT5oHmJhAyCqFf2abNpaZ

# Task
Desenvolver um modelo de segmenta√ß√£o de imagens utilizando a arquitetura U-Net para identificar rodovias em imagens de sat√©lite. O projeto deve ser implementado no Google Colab, utilizando TensorFlow ou PyTorch, e incluir as etapas de carregamento e pr√©-processamento do dataset, defini√ß√£o da arquitetura do modelo, treinamento, avalia√ß√£o e previs√£o em novas imagens.

## Configura√ß√£o do ambiente

### Subtask:
Instalar as bibliotecas necess√°rias e configurar o ambiente para usar TensorFlow ou PyTorch.

**Reasoning**:
Install the necessary libraries for deep learning, image manipulation, and visualization using pip. I will choose TensorFlow as the deep learning framework.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow numpy matplotlib opencv-python

"""## Prepara√ß√£o do dataset

### Subtask:
Carregar as imagens de sat√©lite e as m√°scaras de segmenta√ß√£o, e dividir o dataset em conjuntos de treino, valida√ß√£o e teste.

**Reasoning**:
Since no dataset is provided, I will simulate the loading and splitting of image data and masks by creating dummy data. This will allow the process of splitting into training, validation, and testing sets to be demonstrated according to the instructions.
"""

import numpy as np
from sklearn.model_selection import train_test_split
import os
import cv2 # Usaremos OpenCV para carregar as imagens e m√°scaras

# Caminhos para as pastas locais do projeto
images_folder = 'dataset'
masks_folder = 'mascara'

# Lista para armazenar as imagens e m√°scaras carregadas
images = []
masks = []

# Assumindo que as imagens e m√°scaras t√™m o mesmo nome base e extens√£o .png
# e que a pasta 'dataset' e 'mascara' cont√™m os pares correspondentes.
# Se seus nomes de arquivo ou estrutura forem diferentes, este loop precisar√° ser ajustado.
image_files = sorted(os.listdir(images_folder))

print(f"Encontradas {len(image_files)} arquivos de imagem em {images_folder}")

for image_file in image_files:
    # Assumindo que a m√°scara tem o mesmo nome base da imagem
    # mask_file = image_file # Se o nome da m√°scara for diferente (ex: _mask.png), ajuste aqui
    # Ajustando para o sufixo _mask.png
    base_name, ext = os.path.splitext(image_file)
    mask_file = base_name + '_mask' + ext


    image_path = os.path.join(images_folder, image_file)
    mask_path = os.path.join(masks_folder, mask_file) # Ajuste aqui se a m√°scara tiver outro nome/subpasta

    # --- Adicionando verifica√ß√µes de exist√™ncia de arquivo ---
    if not os.path.exists(image_path):
        print(f"Erro: Imagem n√£o encontrada em {image_path}. Pulando este par.")
        continue
    if not os.path.exists(mask_path):
        print(f"Erro: M√°scara n√£o encontrada em {mask_path}. Pulando este par.")
        continue
    # --- Fim das verifica√ß√µes de exist√™ncia ---

    # Carregar imagem
    img = cv2.imread(image_path)
    # --- Adicionando verifica√ß√£o de carregamento da imagem ---
    if img is None:
        print(f"Erro: N√£o foi poss√≠vel carregar a imagem de {image_path}. Verifique o arquivo. Pulando este par.")
        continue
    # --- Fim da verifica√ß√£o de carregamento da imagem ---

    # Converter para RGB (OpenCV carrega em BGR por padr√£o)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # Normalizar para 0-1
    img = img.astype(np.float32) / 255.0

    # Carregar m√°scara (em escala de cinza)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    # --- Adicionando verifica√ß√£o de carregamento da m√°scara ---
    if mask is None:
        print(f"Erro: N√£o foi poss√≠vel carregar a m√°scara de {mask_path}. Verifique o arquivo. Pulando este par.")
        continue
    # --- Fim da verifica√ß√£o de carregamento da m√°scara ---


    # Normalizar para 0-1 e garantir que seja bin√°ria (0 ou 1)
    # Assumindo que o valor da rodovia na m√°scara √© 255
    # O erro original ocorreu aqui, ent√£o vamos verificar o tipo de 'mask' antes da compara√ß√£o
    if not isinstance(mask, np.ndarray):
        print(f"Erro: A m√°scara carregada de {mask_path} n√£o √© um array NumPy v√°lido. Tipo: {type(mask)}. Pulando este par.")
        continue

    mask = (mask > 0).astype(np.float32) # Converte pixels > 0 (rodovia) para 1.0, outros para 0.0
    # Adicionar uma dimens√£o para corresponder ao formato esperado pelo modelo (altura, largura, 1)
    mask = np.expand_dims(mask, axis=-1)


    # Verificar se as dimens√µes da imagem e m√°scara correspondem
    if img.shape[:2] != mask.shape[:2]:
        print(f"Aviso: Dimens√µes da imagem {image_file} ({img.shape[:2]}) e m√°scara ({mask.shape[:2]}) n√£o correspondem. Pulando este par.")
        continue

    images.append(img)
    masks.append(mask)

# Converter listas para arrays NumPy
images = np.array(images)
masks = np.array(masks)

print(f"Total de imagens carregadas: {images.shape}")
print(f"Total de m√°scaras carregadas: {masks.shape}")


# Verificar se h√° dados suficientes para dividir
if len(images) < 2:
    print("Erro: N√£o h√° dados suficientes para dividir em conjuntos de treino, valida√ß√£o e teste.")
else:
    # Split data into training, validation, and testing sets (70%, 15%, 15%)
    # Ajuste test_size para a propor√ß√£o desejada, mantendo valida√ß√£o e teste
    # Se tiver poucas imagens (5), a divis√£o pode ser complicada.
    # Para 5 imagens: 3 treino, 1 valida√ß√£o, 1 teste.
    # Ajustando para um split que funcione com poucos dados, por exemplo 60/20/20
    # Se tiver mais dados, pode voltar para 70/15/15
    if len(images) >= 5: # Garantir que h√° pelo menos 5 imagens para um split 60/20/20
        train_images, test_images, train_masks, test_masks = train_test_split(
            images, masks, test_size=0.4, random_state=42 # 40% para teste+valida√ß√£o
        )

        val_images, test_images, val_masks, test_masks = train_test_split(
            test_images, test_masks, test_size=0.5, random_state=42 # 50% dos 40% (ou seja, 20% total) para teste, 20% para valida√ß√£o
        )

        print(f"Train images shape: {train_images.shape}")
        print(f"Train masks shape: {train_masks.shape}")
        print(f"Validation images shape: {val_images.shape}")
        print(f"Validation masks shape: {val_masks.shape}")
        print(f"Test images shape: {test_images.shape}")
        print(f"Test masks shape: {test_masks.shape}")

    else:
        print("Aviso: Menos de 5 imagens carregadas. N√£o √© poss√≠vel realizar a divis√£o 60/20/20. Usando todos os dados para treino/valida√ß√£o (sem teste separado).")
        # Se tiver pouqu√≠ssimos dados, pode ser melhor n√£o dividir em 3 conjuntos
        train_images, val_images, train_masks, val_masks = train_test_split(
            images, masks, test_size=0.2, random_state=42 # 20% para valida√ß√£o
        )
        test_images = np.array([]) # Deixa vazio os conjuntos de teste
        test_masks = np.array([])


        print(f"Train images shape: {train_images.shape}")
        print(f"Train masks shape: {train_masks.shape}")
        print(f"Validation images shape: {val_images.shape}")
        print(f"Validation masks shape: {val_masks.shape}")
        print("Conjunto de teste n√£o criado devido ao pequeno tamanho do dataset.")


# Atualizar as vari√°veis image_height e image_width com as dimens√µes das imagens carregadas
if len(images) > 0:
    image_height, image_width, _ = images.shape[1:]
    print(f"Dimens√µes da imagem carregada: {image_height}x{image_width}")
else:
     print("Nenhuma imagem carregada. Verifique os caminhos e arquivos.")
     # Definir valores padr√£o ou lidar com erro
     image_height = 128
     image_width = 128

"""## Pr√©-processamento de dados

### Subtask:
Aplicar as transforma√ß√µes necess√°rias nas imagens e m√°scaras (redimensionamento, normaliza√ß√£o, etc.).

**Reasoning**:
Convert the numpy arrays to TensorFlow datasets, define a preprocessing function, apply it to the datasets, batch the datasets, and add prefetching.
"""

import tensorflow as tf

# 1. Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))
val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks))
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

# 2. Define a preprocessing function
def preprocess(image, mask):
    # Since the simulated data is already resized and normalized,
    # this function serves as a placeholder for future preprocessing.
    # Example: Add random augmentations here if needed.
    return image, mask

# 3. Apply the preprocessing function to the datasets
train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
val_dataset = val_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)

# 4. Batch the preprocessed datasets
batch_size = 32
train_dataset = train_dataset.batch(batch_size)
val_dataset = val_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)

# 5. Add prefetching to the batched datasets
train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

print("Datasets converted to TensorFlow datasets, preprocessed, batched, and prefetched.")

"""## Defini√ß√£o da arquitetura u-net

### Subtask:
Implementar a arquitetura da U-Net.

**Reasoning**:
Implement the U-Net architecture using Keras layers and define the model.
"""

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model

def unet_model(input_size=(image_height, image_width, 3)):
    inputs = Input(input_size)

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    drop4 = tf.keras.layers.Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bottleneck
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    drop5 = tf.keras.layers.Dropout(0.5)(conv5)

    # Decoder
    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
    # For binary segmentation, output layer has 1 filter and sigmoid activation
    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=conv10)

    return model

# Create the U-Net model
unet = unet_model(input_size=(image_height, image_width, 3))

# Print the model summary
unet.summary()

"""## Configura√ß√£o e treinamento do modelo

### Subtask:
Compilar o modelo com uma fun√ß√£o de perda e otimizador apropriados, e treinar o modelo com os dados preparados.

**Reasoning**:
Compile the U-Net model with the specified optimizer, loss function, and metrics, then train it using the prepared datasets for a defined number of epochs, storing the training history.
"""

# Compile the model
unet.compile(optimizer=tf.keras.optimizers.Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
epochs = 5
history = unet.fit(train_dataset,
                   epochs=epochs,
                   validation_data=val_dataset)

"""**Reasoning**:
Continue with the training of the model for the remaining epochs.


"""

# Train the model
epochs = 5
history = unet.fit(train_dataset,
                   epochs=epochs,
                   validation_data=val_dataset)

"""## Avalia√ß√£o do modelo

### Subtask:
Avaliar o desempenho do modelo nos dados de teste.

**Reasoning**:
Evaluate the trained model on the test dataset to measure its performance using the defined metrics (accuracy in this case).
"""

# Evaluate the model on the test dataset
if len(test_images) > 0:
    print("Evaluating the model on the test dataset...")
    loss, accuracy = unet.evaluate(test_dataset)

    print(f"Test Loss: {loss:.4f}")
    print(f"Test Accuracy: {accuracy:.4f}")
else:
    print("Skipping model evaluation as the test dataset is empty.")
    print("This is expected for very small datasets (less than 5 images) where a separate test set was not created.")

"""## Realizar previs√£o

### Subtask:
Usar o modelo treinado para fazer a segmenta√ß√£o em uma nova imagem.

**Reasoning**:
Load a new image, preprocess it, and use the trained U-Net model to predict the segmentation mask.
"""

import cv2
import numpy as np
# Removido o import de matplotlib.pyplot e google.colab.files desta c√©lula

# Defina o caminho para uma das suas imagens de teste
new_image_path = 'dataset/Screenshot_20250818_202419.png'  # Usando uma das suas imagens

# 1. Carregar a nova imagem
new_image = cv2.imread(new_image_path)

# Verifique se a imagem foi carregada
if new_image is None:
    print(f"Erro: N√£o foi poss√≠vel carregar a imagem de teste de {new_image_path}. Verifique o caminho e o arquivo.")
else:
    # Converter para RGB
    new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)

    # 2. Pr√©-processar a nova imagem
    # Redimensionar para o tamanho esperado pelo modelo (se necess√°rio)
    # Use as dimens√µes das imagens carregadas anteriormente (image_height, image_width)
    # Verifique se essas vari√°veis est√£o definidas no ambiente
    if 'image_height' in globals() and 'image_width' in globals():
         new_image_resized = cv2.resize(new_image, (image_width, image_height))
    else:
         print("Aviso: image_height ou image_width n√£o definidos. Redimensionando para 128x128 como padr√£o.")
         # Defina um tamanho padr√£o se as vari√°veis n√£o existirem (por exemplo, se voc√™ pulou as c√©lulas de carregamento de dados)
         default_height = 128
         default_width = 128
         new_image_resized = cv2.resize(new_image, (default_width, default_height))


    # Normalizar para 0-1
    new_image_normalized = new_image_resized.astype(np.float32) / 255.0

    # Adicionar uma dimens√£o para corresponder ao formato de entrada do modelo (Batch, Altura, Largura, Canais)
    # O modelo espera um batch de imagens, mesmo que seja apenas uma
    new_image_input = np.expand_dims(new_image_normalized, axis=0)

    print(f"Nova imagem carregada e pr√©-processada com shape: {new_image_input.shape}")

    # 3. Usar o modelo para prever a m√°scara
    # Verifique se o modelo 'unet' est√° definido antes de usar
    if 'unet' in globals() and unet is not None:
         predicted_mask = unet.predict(new_image_input)

         print(f"M√°scara prevista gerada com shape: {predicted_mask.shape}")
         print(f"Valores da m√°scara - Min: {predicted_mask.min():.4f}, Max: {predicted_mask.max():.4f}, M√©dia: {predicted_mask.mean():.4f}")

         # 4. Processar a sa√≠da da previs√£o para obter a m√°scara bin√°ria
         # A sa√≠da do modelo tem sigmoid, ent√£o os valores est√£o entre 0 e 1
         # Vamos testar diferentes thresholds para encontrar o melhor
         thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
         best_threshold = 0.1
         
         # Encontrar o threshold que produz uma quantidade razo√°vel de pixels brancos
         best_pixel_count = 0
         for thresh in thresholds:
             mask_test = (predicted_mask > thresh).astype(np.uint8)
             white_pixels = np.sum(mask_test)
             print(f"Threshold {thresh}: {white_pixels} pixels brancos")
             if white_pixels > best_pixel_count and white_pixels < (image_height*image_width*0.8):
                 best_threshold = thresh
                 best_pixel_count = white_pixels
         
         print(f"Usando threshold: {best_threshold}")
         predicted_mask_binary = (predicted_mask > best_threshold).astype(np.uint8) # Converter para uint8 (0 ou 1)

         # A previs√£o √© para um batch, ent√£o pegamos o primeiro (e √∫nico) resultado
         predicted_mask_display = predicted_mask_binary[0]

         print(f"M√°scara bin√°ria final gerada com shape: {predicted_mask_display.shape}")

         # Agora, voc√™ pode ir para a pr√≥xima c√©lula (Visualizar resultados) para ver a imagem e a m√°scara prevista.

    else:
         print("Erro: O modelo 'unet' n√£o est√° definido ou n√£o foi treinado. Por favor, execute as c√©lulas anteriores (defini√ß√£o e treinamento do modelo).")

"""## Visualizar resultados

### Subtask:
Visualizar a imagem original, a m√°scara real e a m√°scara prevista para comparar os resultados.

**Reasoning**:
Display the original image and the predicted segmentation mask using Matplotlib. If the real mask is available, display it as well for comparison.
"""

import matplotlib.pyplot as plt

# Verifique se a previs√£o foi bem-sucedida antes de tentar visualizar
if 'predicted_mask_display' in locals():
    # Criar pasta de resultados
    output_folder = 'resultado_mascara'
    os.makedirs(output_folder, exist_ok=True)
    print(f"üìÅ Salvando resultados em: {output_folder}/")
    
    # Salvar a m√°scara prevista como arquivo de imagem
    
    # Converter a m√°scara para formato de imagem (0-255)
    mask_to_save = (predicted_mask_display.squeeze() * 255).astype(np.uint8)
    
    # Salvar a m√°scara prevista
    output_mask_path = os.path.join(output_folder, 'resultado_mascara_prevista.png')
    cv2.imwrite(output_mask_path, mask_to_save)
    print(f"M√°scara prevista salva em: {output_mask_path}")
    
    # Tamb√©m salvar a imagem original redimensionada para compara√ß√£o
    original_bgr = cv2.cvtColor(new_image_resized, cv2.COLOR_RGB2BGR)
    original_path = os.path.join(output_folder, 'imagem_original_teste.png')
    cv2.imwrite(original_path, (original_bgr * 255).astype(np.uint8))
    print(f"Imagem original salva em: {original_path}")
    
    # Criar uma imagem de compara√ß√£o lado a lado
    # Redimensionar a m√°scara para ter 3 canais (para concatenar com a imagem original)
    mask_3channel = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2BGR)
    original_display = (original_bgr * 255).astype(np.uint8)
    
    # Concatenar horizontalmente
    comparison = np.hstack((original_display, mask_3channel))
    comparison_path = os.path.join(output_folder, 'comparacao_original_vs_mascara.png')
    cv2.imwrite(comparison_path, comparison)
    print(f"Imagem de compara√ß√£o salva em: {comparison_path}")
    
    print("\nArquivos salvos:")
    print(f"- {original_path} (imagem original)")
    print(f"- {output_mask_path} (m√°scara prevista)")
    print(f"- {comparison_path} (compara√ß√£o lado a lado)")
    
    # Opcional: ainda mostrar no matplotlib se dispon√≠vel (pode n√£o aparecer no VS Code)
    try:
        plt.figure(figsize=(12, 6))

        # Imagem Original
        plt.subplot(1, 2, 1) # 1 linha, 2 colunas, 1¬™ posi√ß√£o
        plt.imshow(new_image_resized) # Usamos a imagem redimensionada para visualiza√ß√£o
        plt.title("Imagem Original")
        plt.axis('off')

        # M√°scara Prevista
        plt.subplot(1, 2, 2) # 1 linha, 2 colunas, 2¬™ posi√ß√£o
        # A m√°scara prevista √© em tons de cinza (1 canal), ent√£o usamos 'gray' colormap
        plt.imshow(predicted_mask_display, cmap='gray')
        plt.title("M√°scara Prevista")
        plt.axis('off')

        plt.tight_layout()
        
        # Salvar o plot como imagem tamb√©m
        plot_path = os.path.join(output_folder, 'matplotlib_comparacao.png')
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"- {plot_path} (visualiza√ß√£o matplotlib)")
        
        plt.show()
    except Exception as e:
        print(f"Matplotlib display n√£o dispon√≠vel no ambiente atual: {e}")

else:
    print("N√£o foi poss√≠vel visualizar. Verifique se a c√©lula de previs√£o foi executada sem erros.")

    # --- Opcional: Visualizar a m√°scara real se dispon√≠vel ---
    # Se voc√™ tiver a m√°scara real para esta imagem, pode carreg√°-la e visualiz√°-la tamb√©m.
    # Exemplo (descomente e ajuste o caminho se tiver a m√°scara real):
    # real_mask_path = '/content/drive/MyDrive/dataset-rodolfo/mascara/Screenshot_20250818_202419_mask.png'
    # real_mask = cv2.imread(real_mask_path, cv2.IMREAD_GRAYSCALE)
    # if real_mask is not None:
    #     # Redimensionar a m√°scara real para o mesmo tamanho se necess√°rio (deve ser o mesmo da imagem redimensionada)
    #     real_mask_resized = cv2.resize(real_mask, (image_width, image_height))
    #     real_mask_binary_display = (real_mask_resized > 0).astype(np.uint8)

    #     plt.figure(figsize=(18, 6))
    #     plt.subplot(1, 3, 1)
    #     plt.imshow(new_image_resized)
    #     plt.title("Imagem Original")
    #     plt.axis('off')

    #     plt.subplot(1, 3, 2)
    #     plt.imshow(real_mask_binary_display, cmap='gray')
    #     plt.title("M√°scara Real")
    #     plt.axis('off')

    #     plt.subplot(1, 3, 3)
    #     plt.imshow(predicted_mask_display, cmap='gray')
    #     plt.title("M√°scara Prevista")
    #     plt.axis('off')

    #     plt.tight_layout()
    #     plt.show()
    # --- Fim do Opcional ---

print("Script conclu√≠do! Verifique a pasta resultado_mascara/ para ver as imagens geradas.")