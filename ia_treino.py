# -*- coding: utf-8 -*-
"""IA-TREINO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hUOEDUAtikvDT5oHmJhAyCqFf2abNpaZ

# Task
Desenvolver um modelo de segmentação de imagens utilizando a arquitetura U-Net para identificar rodovias em imagens de satélite. O projeto deve ser implementado no Google Colab, utilizando TensorFlow ou PyTorch, e incluir as etapas de carregamento e pré-processamento do dataset, definição da arquitetura do modelo, treinamento, avaliação e previsão em novas imagens.

## Configuração do ambiente

### Subtask:
Instalar as bibliotecas necessárias e configurar o ambiente para usar TensorFlow ou PyTorch.

**Reasoning**:
Install the necessary libraries for deep learning, image manipulation, and visualization using pip. I will choose TensorFlow as the deep learning framework.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow numpy matplotlib opencv-python

"""## Preparação do dataset

### Subtask:
Carregar as imagens de satélite e as máscaras de segmentação, e dividir o dataset em conjuntos de treino, validação e teste.

**Reasoning**:
Since no dataset is provided, I will simulate the loading and splitting of image data and masks by creating dummy data. This will allow the process of splitting into training, validation, and testing sets to be demonstrated according to the instructions.
"""

import numpy as np
from sklearn.model_selection import train_test_split
import os
import cv2 # Usaremos OpenCV para carregar as imagens e máscaras

# Caminhos para as pastas locais do projeto
images_folder = 'dataset'
masks_folder = 'mascara'

# Lista para armazenar as imagens e máscaras carregadas
images = []
masks = []

# Assumindo que as imagens e máscaras têm o mesmo nome base e extensão .png
# e que a pasta 'dataset' e 'mascara' contêm os pares correspondentes.
# Se seus nomes de arquivo ou estrutura forem diferentes, este loop precisará ser ajustado.
image_files = sorted(os.listdir(images_folder))

print(f"Encontradas {len(image_files)} arquivos de imagem em {images_folder}")

for image_file in image_files:
    # Assumindo que a máscara tem o mesmo nome base da imagem
    # mask_file = image_file # Se o nome da máscara for diferente (ex: _mask.png), ajuste aqui
    # Ajustando para o sufixo _mask.png
    base_name, ext = os.path.splitext(image_file)
    mask_file = base_name + '_mask' + ext


    image_path = os.path.join(images_folder, image_file)
    mask_path = os.path.join(masks_folder, mask_file) # Ajuste aqui se a máscara tiver outro nome/subpasta

    # --- Adicionando verificações de existência de arquivo ---
    if not os.path.exists(image_path):
        print(f"Erro: Imagem não encontrada em {image_path}. Pulando este par.")
        continue
    if not os.path.exists(mask_path):
        print(f"Erro: Máscara não encontrada em {mask_path}. Pulando este par.")
        continue
    # --- Fim das verificações de existência ---

    # Carregar imagem
    img = cv2.imread(image_path)
    # --- Adicionando verificação de carregamento da imagem ---
    if img is None:
        print(f"Erro: Não foi possível carregar a imagem de {image_path}. Verifique o arquivo. Pulando este par.")
        continue
    # --- Fim da verificação de carregamento da imagem ---

    # Converter para RGB (OpenCV carrega em BGR por padrão)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # Normalizar para 0-1
    img = img.astype(np.float32) / 255.0

    # Carregar máscara (em escala de cinza)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    # --- Adicionando verificação de carregamento da máscara ---
    if mask is None:
        print(f"Erro: Não foi possível carregar a máscara de {mask_path}. Verifique o arquivo. Pulando este par.")
        continue
    # --- Fim da verificação de carregamento da máscara ---


    # Normalizar para 0-1 e garantir que seja binária (0 ou 1)
    # Assumindo que o valor da rodovia na máscara é 255
    # O erro original ocorreu aqui, então vamos verificar o tipo de 'mask' antes da comparação
    if not isinstance(mask, np.ndarray):
        print(f"Erro: A máscara carregada de {mask_path} não é um array NumPy válido. Tipo: {type(mask)}. Pulando este par.")
        continue

    mask = (mask > 0).astype(np.float32) # Converte pixels > 0 (rodovia) para 1.0, outros para 0.0
    # Adicionar uma dimensão para corresponder ao formato esperado pelo modelo (altura, largura, 1)
    mask = np.expand_dims(mask, axis=-1)


    # Verificar se as dimensões da imagem e máscara correspondem
    if img.shape[:2] != mask.shape[:2]:
        print(f"Aviso: Dimensões da imagem {image_file} ({img.shape[:2]}) e máscara ({mask.shape[:2]}) não correspondem. Pulando este par.")
        continue

    images.append(img)
    masks.append(mask)

# Converter listas para arrays NumPy
images = np.array(images)
masks = np.array(masks)

print(f"Total de imagens carregadas: {images.shape}")
print(f"Total de máscaras carregadas: {masks.shape}")


# Verificar se há dados suficientes para dividir
if len(images) < 2:
    print("Erro: Não há dados suficientes para dividir em conjuntos de treino, validação e teste.")
else:
    # Split data into training, validation, and testing sets (70%, 15%, 15%)
    # Ajuste test_size para a proporção desejada, mantendo validação e teste
    # Se tiver poucas imagens (5), a divisão pode ser complicada.
    # Para 5 imagens: 3 treino, 1 validação, 1 teste.
    # Ajustando para um split que funcione com poucos dados, por exemplo 60/20/20
    # Se tiver mais dados, pode voltar para 70/15/15
    if len(images) >= 5: # Garantir que há pelo menos 5 imagens para um split 60/20/20
        train_images, test_images, train_masks, test_masks = train_test_split(
            images, masks, test_size=0.4, random_state=42 # 40% para teste+validação
        )

        val_images, test_images, val_masks, test_masks = train_test_split(
            test_images, test_masks, test_size=0.5, random_state=42 # 50% dos 40% (ou seja, 20% total) para teste, 20% para validação
        )

        print(f"Train images shape: {train_images.shape}")
        print(f"Train masks shape: {train_masks.shape}")
        print(f"Validation images shape: {val_images.shape}")
        print(f"Validation masks shape: {val_masks.shape}")
        print(f"Test images shape: {test_images.shape}")
        print(f"Test masks shape: {test_masks.shape}")

    else:
        print("Aviso: Menos de 5 imagens carregadas. Não é possível realizar a divisão 60/20/20. Usando todos os dados para treino/validação (sem teste separado).")
        # Se tiver pouquíssimos dados, pode ser melhor não dividir em 3 conjuntos
        train_images, val_images, train_masks, val_masks = train_test_split(
            images, masks, test_size=0.2, random_state=42 # 20% para validação
        )
        test_images = np.array([]) # Deixa vazio os conjuntos de teste
        test_masks = np.array([])


        print(f"Train images shape: {train_images.shape}")
        print(f"Train masks shape: {train_masks.shape}")
        print(f"Validation images shape: {val_images.shape}")
        print(f"Validation masks shape: {val_masks.shape}")
        print("Conjunto de teste não criado devido ao pequeno tamanho do dataset.")


# Atualizar as variáveis image_height e image_width com as dimensões das imagens carregadas
if len(images) > 0:
    image_height, image_width, _ = images.shape[1:]
    print(f"Dimensões da imagem carregada: {image_height}x{image_width}")
else:
     print("Nenhuma imagem carregada. Verifique os caminhos e arquivos.")
     # Definir valores padrão ou lidar com erro
     image_height = 128
     image_width = 128

"""## Pré-processamento de dados

### Subtask:
Aplicar as transformações necessárias nas imagens e máscaras (redimensionamento, normalização, etc.).

**Reasoning**:
Convert the numpy arrays to TensorFlow datasets, define a preprocessing function, apply it to the datasets, batch the datasets, and add prefetching.
"""

import tensorflow as tf

# 1. Convert numpy arrays to TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks))
val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks))
test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_masks))

# 2. Define a preprocessing function
def preprocess(image, mask):
    # Since the simulated data is already resized and normalized,
    # this function serves as a placeholder for future preprocessing.
    # Example: Add random augmentations here if needed.
    return image, mask

# 3. Apply the preprocessing function to the datasets
train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
val_dataset = val_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)
test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)

# 4. Batch the preprocessed datasets
batch_size = 32
train_dataset = train_dataset.batch(batch_size)
val_dataset = val_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)

# 5. Add prefetching to the batched datasets
train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

print("Datasets converted to TensorFlow datasets, preprocessed, batched, and prefetched.")

"""## Definição da arquitetura u-net

### Subtask:
Implementar a arquitetura da U-Net.

**Reasoning**:
Implement the U-Net architecture using Keras layers and define the model.
"""

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model

def unet_model(input_size=(image_height, image_width, 3)):
    inputs = Input(input_size)

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    drop4 = tf.keras.layers.Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bottleneck
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    drop5 = tf.keras.layers.Dropout(0.5)(conv5)

    # Decoder
    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
    # For binary segmentation, output layer has 1 filter and sigmoid activation
    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=conv10)

    return model

# Create the U-Net model
unet = unet_model(input_size=(image_height, image_width, 3))

# Print the model summary
unet.summary()

"""## Configuração e treinamento do modelo

### Subtask:
Compilar o modelo com uma função de perda e otimizador apropriados, e treinar o modelo com os dados preparados.

**Reasoning**:
Compile the U-Net model with the specified optimizer, loss function, and metrics, then train it using the prepared datasets for a defined number of epochs, storing the training history.
"""

# Compile the model
unet.compile(optimizer=tf.keras.optimizers.Adam(),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
epochs = 5
history = unet.fit(train_dataset,
                   epochs=epochs,
                   validation_data=val_dataset)

"""**Reasoning**:
Continue with the training of the model for the remaining epochs.


"""

# Train the model
epochs = 5
history = unet.fit(train_dataset,
                   epochs=epochs,
                   validation_data=val_dataset)

"""## Avaliação do modelo

### Subtask:
Avaliar o desempenho do modelo nos dados de teste.

**Reasoning**:
Evaluate the trained model on the test dataset to measure its performance using the defined metrics (accuracy in this case).
"""

# Evaluate the model on the test dataset
if len(test_images) > 0:
    print("Evaluating the model on the test dataset...")
    loss, accuracy = unet.evaluate(test_dataset)

    print(f"Test Loss: {loss:.4f}")
    print(f"Test Accuracy: {accuracy:.4f}")
else:
    print("Skipping model evaluation as the test dataset is empty.")
    print("This is expected for very small datasets (less than 5 images) where a separate test set was not created.")

"""## Realizar previsão

### Subtask:
Usar o modelo treinado para fazer a segmentação em uma nova imagem.

**Reasoning**:
Load a new image, preprocess it, and use the trained U-Net model to predict the segmentation mask.
"""

import cv2
import numpy as np
# Removido o import de matplotlib.pyplot e google.colab.files desta célula

# Defina o caminho para uma das suas imagens de teste
new_image_path = 'dataset/Screenshot_20250818_202419.png'  # Usando uma das suas imagens

# 1. Carregar a nova imagem
new_image = cv2.imread(new_image_path)

# Verifique se a imagem foi carregada
if new_image is None:
    print(f"Erro: Não foi possível carregar a imagem de teste de {new_image_path}. Verifique o caminho e o arquivo.")
else:
    # Converter para RGB
    new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)

    # 2. Pré-processar a nova imagem
    # Redimensionar para o tamanho esperado pelo modelo (se necessário)
    # Use as dimensões das imagens carregadas anteriormente (image_height, image_width)
    # Verifique se essas variáveis estão definidas no ambiente
    if 'image_height' in globals() and 'image_width' in globals():
         new_image_resized = cv2.resize(new_image, (image_width, image_height))
    else:
         print("Aviso: image_height ou image_width não definidos. Redimensionando para 128x128 como padrão.")
         # Defina um tamanho padrão se as variáveis não existirem (por exemplo, se você pulou as células de carregamento de dados)
         default_height = 128
         default_width = 128
         new_image_resized = cv2.resize(new_image, (default_width, default_height))


    # Normalizar para 0-1
    new_image_normalized = new_image_resized.astype(np.float32) / 255.0

    # Adicionar uma dimensão para corresponder ao formato de entrada do modelo (Batch, Altura, Largura, Canais)
    # O modelo espera um batch de imagens, mesmo que seja apenas uma
    new_image_input = np.expand_dims(new_image_normalized, axis=0)

    print(f"Nova imagem carregada e pré-processada com shape: {new_image_input.shape}")

    # 3. Usar o modelo para prever a máscara
    # Verifique se o modelo 'unet' está definido antes de usar
    if 'unet' in globals() and unet is not None:
         predicted_mask = unet.predict(new_image_input)

         print(f"Máscara prevista gerada com shape: {predicted_mask.shape}")
         print(f"Valores da máscara - Min: {predicted_mask.min():.4f}, Max: {predicted_mask.max():.4f}, Média: {predicted_mask.mean():.4f}")

         # 4. Processar a saída da previsão para obter a máscara binária
         # A saída do modelo tem sigmoid, então os valores estão entre 0 e 1
         # Vamos testar diferentes thresholds para encontrar o melhor
         thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
         best_threshold = 0.1
         
         # Encontrar o threshold que produz uma quantidade razoável de pixels brancos
         best_pixel_count = 0
         for thresh in thresholds:
             mask_test = (predicted_mask > thresh).astype(np.uint8)
             white_pixels = np.sum(mask_test)
             print(f"Threshold {thresh}: {white_pixels} pixels brancos")
             if white_pixels > best_pixel_count and white_pixels < (image_height*image_width*0.8):
                 best_threshold = thresh
                 best_pixel_count = white_pixels
         
         print(f"Usando threshold: {best_threshold}")
         predicted_mask_binary = (predicted_mask > best_threshold).astype(np.uint8) # Converter para uint8 (0 ou 1)

         # A previsão é para um batch, então pegamos o primeiro (e único) resultado
         predicted_mask_display = predicted_mask_binary[0]

         print(f"Máscara binária final gerada com shape: {predicted_mask_display.shape}")

         # Agora, você pode ir para a próxima célula (Visualizar resultados) para ver a imagem e a máscara prevista.

    else:
         print("Erro: O modelo 'unet' não está definido ou não foi treinado. Por favor, execute as células anteriores (definição e treinamento do modelo).")

"""## Visualizar resultados

### Subtask:
Visualizar a imagem original, a máscara real e a máscara prevista para comparar os resultados.

**Reasoning**:
Display the original image and the predicted segmentation mask using Matplotlib. If the real mask is available, display it as well for comparison.
"""

import matplotlib.pyplot as plt

# Verifique se a previsão foi bem-sucedida antes de tentar visualizar
if 'predicted_mask_display' in locals():
    # Criar pasta de resultados
    output_folder = 'resultado_mascara'
    os.makedirs(output_folder, exist_ok=True)
    print(f"📁 Salvando resultados em: {output_folder}/")
    
    # Salvar a máscara prevista como arquivo de imagem
    
    # Converter a máscara para formato de imagem (0-255)
    mask_to_save = (predicted_mask_display.squeeze() * 255).astype(np.uint8)
    
    # Salvar a máscara prevista
    output_mask_path = os.path.join(output_folder, 'resultado_mascara_prevista.png')
    cv2.imwrite(output_mask_path, mask_to_save)
    print(f"Máscara prevista salva em: {output_mask_path}")
    
    # Também salvar a imagem original redimensionada para comparação
    original_bgr = cv2.cvtColor(new_image_resized, cv2.COLOR_RGB2BGR)
    original_path = os.path.join(output_folder, 'imagem_original_teste.png')
    cv2.imwrite(original_path, (original_bgr * 255).astype(np.uint8))
    print(f"Imagem original salva em: {original_path}")
    
    # Criar uma imagem de comparação lado a lado
    # Redimensionar a máscara para ter 3 canais (para concatenar com a imagem original)
    mask_3channel = cv2.cvtColor(mask_to_save, cv2.COLOR_GRAY2BGR)
    original_display = (original_bgr * 255).astype(np.uint8)
    
    # Concatenar horizontalmente
    comparison = np.hstack((original_display, mask_3channel))
    comparison_path = os.path.join(output_folder, 'comparacao_original_vs_mascara.png')
    cv2.imwrite(comparison_path, comparison)
    print(f"Imagem de comparação salva em: {comparison_path}")
    
    print("\nArquivos salvos:")
    print(f"- {original_path} (imagem original)")
    print(f"- {output_mask_path} (máscara prevista)")
    print(f"- {comparison_path} (comparação lado a lado)")
    
    # Opcional: ainda mostrar no matplotlib se disponível (pode não aparecer no VS Code)
    try:
        plt.figure(figsize=(12, 6))

        # Imagem Original
        plt.subplot(1, 2, 1) # 1 linha, 2 colunas, 1ª posição
        plt.imshow(new_image_resized) # Usamos a imagem redimensionada para visualização
        plt.title("Imagem Original")
        plt.axis('off')

        # Máscara Prevista
        plt.subplot(1, 2, 2) # 1 linha, 2 colunas, 2ª posição
        # A máscara prevista é em tons de cinza (1 canal), então usamos 'gray' colormap
        plt.imshow(predicted_mask_display, cmap='gray')
        plt.title("Máscara Prevista")
        plt.axis('off')

        plt.tight_layout()
        
        # Salvar o plot como imagem também
        plot_path = os.path.join(output_folder, 'matplotlib_comparacao.png')
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"- {plot_path} (visualização matplotlib)")
        
        plt.show()
    except Exception as e:
        print(f"Matplotlib display não disponível no ambiente atual: {e}")

else:
    print("Não foi possível visualizar. Verifique se a célula de previsão foi executada sem erros.")

    # --- Opcional: Visualizar a máscara real se disponível ---
    # Se você tiver a máscara real para esta imagem, pode carregá-la e visualizá-la também.
    # Exemplo (descomente e ajuste o caminho se tiver a máscara real):
    # real_mask_path = '/content/drive/MyDrive/dataset-rodolfo/mascara/Screenshot_20250818_202419_mask.png'
    # real_mask = cv2.imread(real_mask_path, cv2.IMREAD_GRAYSCALE)
    # if real_mask is not None:
    #     # Redimensionar a máscara real para o mesmo tamanho se necessário (deve ser o mesmo da imagem redimensionada)
    #     real_mask_resized = cv2.resize(real_mask, (image_width, image_height))
    #     real_mask_binary_display = (real_mask_resized > 0).astype(np.uint8)

    #     plt.figure(figsize=(18, 6))
    #     plt.subplot(1, 3, 1)
    #     plt.imshow(new_image_resized)
    #     plt.title("Imagem Original")
    #     plt.axis('off')

    #     plt.subplot(1, 3, 2)
    #     plt.imshow(real_mask_binary_display, cmap='gray')
    #     plt.title("Máscara Real")
    #     plt.axis('off')

    #     plt.subplot(1, 3, 3)
    #     plt.imshow(predicted_mask_display, cmap='gray')
    #     plt.title("Máscara Prevista")
    #     plt.axis('off')

    #     plt.tight_layout()
    #     plt.show()
    # --- Fim do Opcional ---

print("Script concluído! Verifique a pasta resultado_mascara/ para ver as imagens geradas.")